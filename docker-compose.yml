version: '3.10'

services:
  # Докер служба для оркестратора, чтобы он мог поднимать отдельные докеры под отдельные раны
  dagit:
    build:
      context: .
      dockerfile: ./dockerfile_dagster
    entrypoint:
      - dagster
      - dev
      - -h
      - "0.0.0.0"
      - -p
      - ${DAGSTER_PORT}
      - -w
      - workspace.yaml
    container_name: dagster
    environment:
        MLOPS_DB_USER: ${MLOPS_DB_USER}
        MLOPS_DB_PASSWORD: ${MLOPS_DB_PASSWORD}
        MLOPS_DB_PORT: ${MLOPS_DB_PORT}
        DAGSTER_DB: ${DAGSTER_DB}
        MLFLOW_PORT: ${MLFLOW_PORT}
    volumes:
      - ./src:/opt/dagster/app
      - ./data:/opt/dagster/data
      - ./dagster.yaml:/opt/dagster/dagster_home/dagster.yaml
      - /var/run/docker.sock:/var/run/docker.sock
    expose:
      - "${DAGSTER_PORT}"
    ports:
      - "${DAGSTER_PORT}:${DAGSTER_PORT}"
    networks:
      - rent_project

  mlops_db:
    image: postgres:14
    restart: always
    container_name: mlops_db
    volumes: 
      - ./data/postgresql:/var/lib/postgresql/data
      - ./data/db_init.sh:/docker-entrypoint-initdb.d/db_init.sh
    environment: 
      - MLFLOW_DB=${MLFLOW_DB}
      - DAGSTER_DB=${DAGSTER_DB}
      - POSTGRES_USER=${MLOPS_DB_USER}
      - POSTGRES_PASSWORD=${MLOPS_DB_PASSWORD}
    expose:
      - ${MLOPS_DB_PORT}
    command: -p ${MLOPS_DB_PORT}
    networks:
      - rent_project
  # data lake для хранения мелких артифактов и моделей
  s3:

    image: minio/minio
    restart: always
    container_name: mlflow_s3
    ports:
      - "${S3_API_PORT}:${S3_API_PORT}"
      - "${S3_CONSOLE_PORT}:${S3_CONSOLE_PORT}"
    volumes:
      - ./data/s3:/data
    environment:
      MINIO_ACCESS_KEY: ${AWS_ACCESS_KEY_ID}
      MINIO_SECRET_KEY: ${AWS_SECRET_ACCESS_KEY}
    command: server --address ":${S3_API_PORT}" --console-address ":${S3_CONSOLE_PORT}" /data/
    networks:
      - rent_project
  # Сервер трекинга и организации ML работ
  mlflow_server:
    image: mlflow_server
    restart: always
    build:

      context: .
      dockerfile: ./dockerfile_mlflow
    container_name: mlflow_server
    environment:
      - BACKEND=postgresql://${MLOPS_DB_USER}:${MLOPS_DB_PASSWORD}@mlops_db:${MLOPS_DB_PORT}/${MLFLOW_DB}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - ARTIFACTS=s3://${AWS_BUCKET_NAME}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:${S3_API_PORT}
    ports:
      - ${MLFLOW_PORT}:${MLFLOW_PORT}
    command: 
      - sh
      - -c
      - mlflow server 
        --host 0.0.0.0
        --port ${MLFLOW_PORT}
        --serve-artifacts
        --backend-store-uri $${BACKEND} 
        --artifacts-destination $${ARTIFACTS}
    depends_on: 
      - mlops_db
      - s3
    networks:
      - rent_project

networks:
  rent_project:
    driver: bridge
    name : 'rent_project'

